{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "add65585",
   "metadata": {},
   "source": [
    "### DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d30658",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Mapping of source XML files to their destination folders and output filenames.\n",
    "# This dictionary drives the entire script.\n",
    "file_mappings = {\n",
    "    'data/processed/laptop_14': {\n",
    "        'data_training': 'data/raw/SemEval 2014 laptops - training.xml',\n",
    "        'data_validation': 'data/raw/SemEval 2014 laptops - validation.xml'\n",
    "    },\n",
    "    'data/processed/restaurants_14': {\n",
    "        'data_training': 'data/raw/SemEval 2014 restaurants - training.xml',\n",
    "        'data_validation': 'data/raw/SemEval 2014 restaurants - validation.xml'\n",
    "    },\n",
    "    'data/processed/restaurants_15': {\n",
    "        'data_training': 'data/raw/SemEval 2015 restaurants - training.xml',\n",
    "        'data_validation': 'data/raw/SemEval 2015 restaurants - validation.xml'\n",
    "    },\n",
    "    'data/processed/restaurants_16': {\n",
    "        'data_training': 'data/raw/SemEval16_Restaurants_Train.xml',\n",
    "        'data_validation': 'data/raw/SemEval16_Restaurants_Test.xml'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Starting the XML to CSV conversion process...\")\n",
    "\n",
    "# --- Main script execution starts here ---\n",
    "\n",
    "# Iterate through the top-level keys of the mapping, which represent the folders to be created.\n",
    "for output_folder, files in file_mappings.items():\n",
    "    # Create the destination folder (e.g., 'laptop_14') if it doesn't already exist.\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    print(f\"\\nCreated/Verified folder: '{output_folder}'\")\n",
    "\n",
    "    # Iterate through the files specified for the current folder.\n",
    "    for output_name, input_xml in files.items():\n",
    "        # Construct the full path for the output CSV file (e.g., 'laptop_14/data_training.csv').\n",
    "        output_csv_path = os.path.join(output_folder, f\"{output_name}.csv\")\n",
    "        \n",
    "        print(f\"  - Parsing '{input_xml}' -> '{output_csv_path}'\")\n",
    "\n",
    "        # Use a try-except block to handle potential errors like a missing file or malformed XML.\n",
    "        try:\n",
    "            tree = ET.parse(input_xml)\n",
    "            root = tree.getroot()\n",
    "        except (ET.ParseError, FileNotFoundError) as e:\n",
    "            print(f\"    ERROR: Could not process file {input_xml}. Reason: {e}\")\n",
    "            # If an error occurs, skip this file and continue with the next one.\n",
    "            continue\n",
    "\n",
    "        # Open the target CSV file in write mode.\n",
    "        with open(output_csv_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "            csv_writer = csv.writer(csv_file)\n",
    "            # Write the header row for the CSV.\n",
    "            csv_writer.writerow(['sentence', 'aspect_term', 'sentiment', 'from', 'to'])\n",
    "\n",
    "            # Determine how to find sentences based on the XML root tag.\n",
    "            # Some files use <sentences> as the root, others use <Reviews>.\n",
    "            sentences_to_process = []\n",
    "            if root.tag == 'sentences':\n",
    "                sentences_to_process = root.findall('sentence')\n",
    "            elif root.tag == 'Reviews':\n",
    "                for review in root.findall('Review'):\n",
    "                    sentences_tag = review.find('sentences')\n",
    "                    if sentences_tag is not None:\n",
    "                        sentences_to_process.extend(sentences_tag.findall('sentence'))\n",
    "\n",
    "            # Process each sentence that was found.\n",
    "            for sentence in sentences_to_process:\n",
    "                text_element = sentence.find('text')\n",
    "                if text_element is None or text_element.text is None:\n",
    "                    continue\n",
    "                sentence_text = text_element.text.strip()\n",
    "\n",
    "                # Handle the structure used in 2014 datasets: <aspectTerms><aspectTerm/></aspectTerms>\n",
    "                aspect_terms_element = sentence.find('aspectTerms')\n",
    "                if aspect_terms_element is not None:\n",
    "                    for aspect_term in aspect_terms_element.findall('aspectTerm'):\n",
    "                        term = aspect_term.get('term')\n",
    "                        polarity = aspect_term.get('polarity')\n",
    "                        from_ = aspect_term.get('from')\n",
    "                        to_ = aspect_term.get('to')\n",
    "                        if term and polarity:\n",
    "                            csv_writer.writerow([sentence_text, term, polarity, from_, to_])\n",
    "                    \n",
    "\n",
    "                # Handle the structure used in 2015/2016 datasets: <Opinions><Opinion/></Opinions>\n",
    "                opinions_element = sentence.find('Opinions')\n",
    "                if opinions_element is not None:\n",
    "                    for opinion in opinions_element.findall('Opinion'):\n",
    "                        target = opinion.get('target')\n",
    "                        polarity = opinion.get('polarity')\n",
    "                        from_ = aspect_term.get('from')\n",
    "                        to_ = aspect_term.get('to')\n",
    "                        # Write row only if the target is not 'NULL'\n",
    "                        if target and target.lower() != 'null' and polarity:\n",
    "                            csv_writer.writerow([sentence_text, target, polarity, from_, to_])\n",
    "\n",
    "print(\"\\nProcessing complete. All files have been converted.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a7da99",
   "metadata": {},
   "source": [
    "### ZERO SHOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f135db26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "import csv\n",
    "import time\n",
    "import os\n",
    "\n",
    "start = time.time()\n",
    "for model_ in ['meta-llama/Meta-Llama-3-8B-Instruct', 'meta-llama/Meta-Llama-3-70B-Instruct', 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'meta-llama/Meta-Llama-3.3-70B-Instruct']:\n",
    "# Initialize the client with the model you want to use\n",
    "    client = InferenceClient(model=model_, token=\"YOUR HUGGINGFACE TOKEN\")\n",
    "\n",
    "    for dataset in ['laptop_14', 'restaurants_14', 'restaurants_15', 'restaurants_16']:\n",
    "        # interate through data_validation.csv\n",
    "        data_validation_path = os.path.join('data', 'processed', dataset, 'data_validation.csv')\n",
    "        with open(data_validation_path, 'r', newline='', encoding='utf-8') as infile:\n",
    "            csv_reader = csv.DictReader(infile)\n",
    "            \n",
    "            # Prepare the messages for the chat completion\n",
    "            sentiments_original = []\n",
    "            sentiments_predicted = []\n",
    "            # loop through ten first rows\n",
    "            for row in csv_reader:\n",
    "                sentence_text = row.get('sentence')\n",
    "                term = row.get('aspect_term')\n",
    "                original_polarity = row.get('sentiment')\n",
    "                from_ = row.get('from')\n",
    "                to_ = row.get('to')\n",
    "\n",
    "                if not sentence_text or not term or not original_polarity:\n",
    "                    continue\n",
    "\n",
    "                prompt = f\"\"\"\n",
    "        Instruction:\n",
    "        Analyze the sentiment of the aspect term within the given sentence. The aspect term is highlighted by quotes. Your answer must be one of the following three options: 'positive', 'negative', 'neutral'. Do not provide any explanation or other text.\n",
    "        Sentence:\n",
    "        \"{sentence_text}\"\n",
    "        Aspect Term:\n",
    "        \"{term}\"\n",
    "\n",
    "        Location of the aspect term in the sentence is from {from_} character to {to_} character.\n",
    "        \n",
    "        Sentiment:\n",
    "        \"\"\"\n",
    "                sentiments_original.append(original_polarity)\n",
    "\n",
    "                # Send the prompt\n",
    "                response = client.chat_completion(messages=[{\"role\": \"user\", \"content\": prompt}], temperature=0.0)\n",
    "\n",
    "                sentiments_predicted.append(response.choices[0].message[\"content\"])\n",
    "                time.sleep(0.5)\n",
    "\n",
    "        # calculate accuracy\n",
    "        correct_predictions = sum(\n",
    "            1 for original, predicted in zip(sentiments_original, sentiments_predicted)\n",
    "            if original.lower() == predicted.lower()\n",
    "        )\n",
    "        accuracy = correct_predictions / len(sentiments_original) * 100\n",
    "\n",
    "        # calculate F1 score\n",
    "        from sklearn.metrics import f1_score\n",
    "        # Convert sentiments to numerical values for F1 score calculation\n",
    "        sentiment_map = {'positive': 1, 'negative': -1, 'neutral': 0}\n",
    "        y_true = [sentiment_map[sentiment.lower()] for sentiment in sentiments_original]\n",
    "        y_pred = [sentiment_map[sentiment.lower()] for sentiment in sentiments_predicted]\n",
    "        f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "        print(f\"\\n\\n________________________\")\n",
    "        print(f\"Model: {model_}\")\n",
    "        print(f\"Dataset: {dataset}\")\n",
    "        print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "end = time.time()\n",
    "print(f\"\\n\\nTotal execution time: {end - start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba8939d",
   "metadata": {},
   "source": [
    "### FEW SHOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe57d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "import csv\n",
    "import time\n",
    "import os\n",
    "\n",
    "start = time.time()\n",
    "for model_ in ['meta-llama/Meta-Llama-3-8B-Instruct', 'meta-llama/Meta-Llama-3-70B-Instruct', 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'meta-llama/Meta-Llama-3.3-70B-Instruct']:\n",
    "# Initialize the client with the model you want to use\n",
    "    client = InferenceClient(model=model_, token=\"YOUR HUGGINGFACE TOKEN\")\n",
    "\n",
    "    for dataset in ['laptop_14', 'restaurants_14', 'restaurants_15', 'restaurants_16']:\n",
    "        # interate through data_validation.csv\n",
    "        data_validation_path = os.path.join('data', 'processed', dataset, 'data_validation.csv')\n",
    "        with open(data_validation_path, 'r', newline='', encoding='utf-8') as infile:\n",
    "            csv_reader = csv.DictReader(infile)\n",
    "            \n",
    "            # Prepare the messages for the chat completion\n",
    "            sentiments_original = []\n",
    "            sentiments_predicted = []\n",
    "            # loop through ten first rows\n",
    "            for row in csv_reader:\n",
    "                sentence_text = row.get('sentence')\n",
    "                term = row.get('aspect_term')\n",
    "                original_polarity = row.get('sentiment')\n",
    "                from_ = row.get('from')\n",
    "                to_ = row.get('to')\n",
    "\n",
    "                if not sentence_text or not term or not original_polarity:\n",
    "                    continue\n",
    "\n",
    "                few_shot_prompt = f\"\"\"\n",
    "Instruction:\n",
    "Analyze the sentiment of the aspect term within the given sentence. The aspect term is highlighted by quotes. Your answer must be one of the following three options: 'positive', 'negative', 'neutral'. Do not provide any explanation or other text.\n",
    "\n",
    "[Example 1]\n",
    "Sentence: \"The ambiance is fantastic and the food is even better.\"\n",
    "Aspect Term: \"food\"\n",
    "Location of the aspect term in the sentence is from 35 character to 38 character.\n",
    "Sentiment:\n",
    "positive\n",
    "\n",
    "[Example 2]\n",
    "Sentence: \"While the staff was friendly, the prices were outrageous.\"\n",
    "Aspect Term: \"prices\"\n",
    "Location of the aspect term in the sentence is from 35 character to 40 character.\n",
    "Sentiment:\n",
    "negative\n",
    "\n",
    "[Example 3]\n",
    "Sentence: \"The laptop's screen is 14 inches.\"\n",
    "Aspect Term: \"screen\"\n",
    "Location of the aspect term in the sentence is from 14 character to 19 character.\n",
    "Sentiment:\n",
    "neutral\n",
    "\n",
    "[Example 4]\n",
    "Sentence: \"The service was exceptionally quick and attentive.\"\n",
    "Aspect Term: \"service\"\n",
    "Location of the aspect term in the sentence is from 5 character to 11 character.\n",
    "Sentiment:\n",
    "positive\n",
    "\n",
    "[Example 5]\n",
    "Sentence: \"I found the keyboard to be a bit cramped and uncomfortable for long typing sessions.\"\n",
    "Aspect Term: \"keyboard\"\n",
    "Location of the aspect term in the sentence is from 13 character to 20 character.\n",
    "Sentiment:\n",
    "negative\n",
    "\n",
    "[Example 6]\n",
    "Sentence: \"The restaurant is located on the main street.\"\n",
    "Aspect Term: \"restaurant\"\n",
    "Location of the aspect term in the sentence is from 5 character to 14 character.\n",
    "Sentiment:\n",
    "neutral\n",
    "\n",
    "[Task]\n",
    "Sentence: \"{sentence_text}\"\n",
    "Aspect Term: \"{term}\"\n",
    "Location of the aspect term in the sentence is from {from_} character to {to_} character.\n",
    "Sentiment:\n",
    "\"\"\"\n",
    "                sentiments_original.append(original_polarity)\n",
    "\n",
    "                # Send the prompt\n",
    "                response = client.chat_completion(messages=[{\"role\": \"user\", \"content\": few_shot_prompt}], temperature=0.0)\n",
    "\n",
    "                sentiments_predicted.append(response.choices[0].message[\"content\"])\n",
    "                time.sleep(0.5)\n",
    "\n",
    "        # calculate accuracy\n",
    "        correct_predictions = sum(\n",
    "            1 for original, predicted in zip(sentiments_original, sentiments_predicted)\n",
    "            if original.lower() == predicted.lower()\n",
    "        )\n",
    "        accuracy = correct_predictions / len(sentiments_original) * 100\n",
    "\n",
    "        # calculate F1 score\n",
    "        from sklearn.metrics import f1_score\n",
    "        # Convert sentiments to numerical values for F1 score calculation\n",
    "        sentiment_map = {'positive': 1, 'negative': -1, 'neutral': 0}\n",
    "        y_true = [sentiment_map[sentiment.lower()] for sentiment in sentiments_original]\n",
    "        y_pred = [sentiment_map[sentiment.lower()] for sentiment in sentiments_predicted]\n",
    "        f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "        print(f\"\\n\\n________________________\")\n",
    "        print(f\"Model: {model_}\")\n",
    "        print(f\"Dataset: {dataset}\")\n",
    "        print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "end = time.time()\n",
    "print(f\"\\n\\nTotal execution time: {end - start:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
